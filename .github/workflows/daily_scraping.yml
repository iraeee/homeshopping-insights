name: Daily Scraping with Compression

on:
  schedule:
    - cron: '56 14 * * *'  # 매일 23:56 (KST) - UTC로는 14:56
    - cron: '0 */2 * * *'  # 2시간마다 실행
  push:
    branches: [ main ]
    paths:
      - 'scrape_schedule.py'
      - 'health_check.py'
      - 'cookie_updater.py'
      - 'compress_and_backup.py'
      - 'decompress_db.py'
  workflow_dispatch:
    inputs:
      date:
        description: 'Date to scrape (YYMMDD format, e.g., 241209)'
        required: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - uses: actions/checkout@v3
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 pandas openpyxl zstandard
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    
    - name: Decompress existing DB if exists
      run: |
        if [ -f "decompress_db.py" ]; then
          python decompress_db.py
        elif [ -f "schedule.db.zst" ]; then
          echo "Manual decompression..."
          python -c "import zstandard;import os;d=zstandard.ZstdDecompressor();open('schedule.db','wb').write(d.decompress(open('schedule.db.zst','rb').read()))"
        fi
    
    - name: Run health check
      run: |
        if [ -f "health_check.py" ]; then
          python health_check.py || echo "Health check warnings detected"
        fi
    
    - name: Run cookie updater
      run: |
        if [ -f "cookie_updater.py" ]; then
          python cookie_updater.py || echo "Cookie update completed"
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Run scraping
      run: |
        if [ "${{ github.event.inputs.date }}" != "" ]; then
          echo "Manual date provided: ${{ github.event.inputs.date }}"
          python scrape_schedule.py --date ${{ github.event.inputs.date }}
        else
          python scrape_schedule.py
        fi
    
    - name: Check data quality
      run: |
        if [ -f "check_data.py" ]; then
          python check_data.py || true
        fi
    
    - name: Update aggregate tables
      run: |
        if [ -f "update_aggregate_tables.py" ]; then
          python update_aggregate_tables.py || echo "Aggregate update completed"
        fi
    
    - name: Compress and backup DB
      run: |
        if [ -f "compress_and_backup.py" ]; then
          python compress_and_backup.py
        else
          echo "Using simple compression..."
          if [ -f "schedule.db" ]; then
            python -c "import zstandard;d=open('schedule.db','rb').read();c=zstandard.ZstdCompressor(3);open('schedule.db.zst','wb').write(c.compress(d))"
            rm -f schedule.db
            echo "Compression complete"
          fi
        fi
    
    - name: Generate README
      run: |
        if [ -f "generate_readme.py" ]; then
          python generate_readme.py || echo "README generation completed"
        fi
    
    - name: Commit and push if changed
      run: |
        git config --global user.email "action@github.com"
        git config --global user.name "GitHub Action"
        git add -A
        git diff --quiet && git diff --staged --quiet || (git commit -m "Update DB and backups [$(date +'%Y-%m-%d %H:%M:%S')]" && git push)
