name: Daily Scraping with Compression

on:
  schedule:
    # 오전 7시~오후 10시: 매시간 (KST 07:00-22:00 = UTC 22:00-13:00)
    - cron: '0 22,23 * * *'  # KST 07:00, 08:00
    - cron: '0 0-13 * * *'   # KST 09:00-22:00
    
    # 밤 11시대 집중 실행
    - cron: '30 14 * * *'  # KST 23:30
    - cron: '40 14 * * *'  # KST 23:40
    - cron: '50 14 * * *'  # KST 23:50
    - cron: '56 14 * * *'  # KST 23:56
    
  push:
    branches: [ main ]
    paths:
      - 'scrape_schedule.py'
      - 'health_check.py'
      - 'cookie_updater.py'
      - 'compress_and_backup.py'
  workflow_dispatch:
    inputs:
      date:
        description: 'Date to scrape (YYMMDD format, e.g., 241209)'
        required: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - uses: actions/checkout@v3
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 pandas openpyxl zstandard pytz
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    
    - name: Decompress existing DB if exists
      run: |
        if [ -f "schedule.db.zst" ]; then
          echo "Decompressing existing DB..."
          python -c "
        import zstandard as zstd
        import os
        
        if os.path.exists('schedule.db.zst'):
            with open('schedule.db.zst', 'rb') as compressed:
                dctx = zstd.ZstdDecompressor()
                with open('schedule.db', 'wb') as output:
                    output.write(dctx.decompress(compressed.read()))
            print('Decompression complete')
        "
        fi
    
    - name: Run health check
      run: |
        if [ -f "health_check.py" ]; then
          python health_check.py || echo "Health check warnings detected"
        fi
    
    - name: Run cookie updater
      run: |
        if [ -f "cookie_updater.py" ]; then
          python cookie_updater.py || echo "Cookie update completed"
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Run scraping
      run: |
        if [ "${{ github.event.inputs.date }}" != "" ]; then
          echo "Manual date provided: ${{ github.event.inputs.date }}"
          python scrape_schedule.py --date ${{ github.event.inputs.date }}
        else
          python scrape_schedule.py
        fi
    
    - name: Check data quality
      run: |
        if [ -f "check_data.py" ]; then
          python check_data.py || true
        fi
    
    - name: Update aggregate tables
      run: |
        if [ -f "update_aggregate_tables.py" ]; then
          python update_aggregate_tables.py || echo "Aggregate update completed"
        fi
    
    - name: Compress and backup DB
      run: |
        if [ -f "compress_and_backup.py" ]; then
          python compress_and_backup.py
        else
          echo "Using simple compression..."
          python -c "
        import zstandard as zstd
        import os
        
        if os.path.exists('schedule.db'):
            print('Compressing DB...')
            with open('schedule.db', 'rb') as f_in:
                data = f_in.read()
            
            cctx = zstd.ZstdCompressor(level=3)
            compressed = cctx.compress(data)
            
            with open('schedule.db.zst', 'wb') as f_out:
                f_out.write(compressed)
            
            original_size = os.path.getsize('schedule.db') / (1024 * 1024)
            compressed_size = os.path.getsize('schedule.db.zst') / (1024 * 1024)
            print(f'Compressed: {original_size:.1f}MB to {compressed_size:.1f}MB')
            
            os.remove('schedule.db')
            print('Original DB removed')
        "
        fi
    
    - name: Generate README
      run: |
        if [ -f "generate_readme.py" ]; then
          python generate_readme.py || echo "README generation completed"
        fi
    
    - name: Commit and push if changed
      run: |
        git config --global user.email "action@github.com"
        git config --global user.name "GitHub Action"
        
        # Pull latest changes first to avoid conflicts
        git pull origin main --rebase --strategy-option=theirs || true
        
        git add -A
        git diff --quiet && git diff --staged --quiet || (git commit -m "Update DB and backups [$(TZ=Asia/Seoul date +'%Y-%m-%d %H:%M:%S')]" && git push)
