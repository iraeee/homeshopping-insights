name: Test Labangba API Access

on:
  workflow_dispatch:
  push:
    paths:
      - '.github/workflows/test_api.yml'

jobs:
  test-api-access:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install requests
      run: pip install requests
    
    - name: Test 1 - Basic Connection
      run: |
        python3 << 'PYTHON_SCRIPT'
        import requests
        print('='*60)
        print('TEST 1: Basic Connection Test')
        print('='*60)
        
        try:
            response = requests.get('https://live.ecomm-data.com/schedule/hs', timeout=10)
            print(f'Main page status: {response.status_code}')
            
            if response.status_code == 403:
                print('BLOCKED: GitHub Actions IP is blocked')
                exit(1)
            elif response.status_code == 200:
                print('SUCCESS: Main page accessible')
            else:
                print(f'WARNING: Unexpected status: {response.status_code}')
                
        except Exception as e:
            print(f'ERROR: Connection failed: {e}')
            exit(1)
        PYTHON_SCRIPT
    
    - name: Test 2 - API without Cookie
      run: |
        python3 << 'PYTHON_SCRIPT'
        import requests
        from datetime import datetime
        
        print('='*60)
        print('TEST 2: API Access without Cookie')
        print('='*60)
        
        date_str = datetime.now().strftime('%y%m%d')
        
        response = requests.post(
            'https://live.ecomm-data.com/schedule/list_hs',
            json={'date': date_str},
            headers={'Content-Type': 'application/json'},
            timeout=10
        )
        
        print(f'API status: {response.status_code}')
        
        if response.status_code == 200:
            data = response.json()
            if 'list' in data:
                items = data['list']
                print(f'SUCCESS: Got {len(items)} items')
                with_sales = sum(1 for item in items if item.get('sales_amt') not in [None, 0])
                print(f'Sales data: {with_sales}/{len(items)}')
        PYTHON_SCRIPT
    
    - name: Test 3 - With Session and Cookie
      env:
        COOKIE: ${{ secrets.LABANGBA_COOKIE }}
      run: |
        python3 << 'PYTHON_SCRIPT'
        import requests
        import os
        from datetime import datetime
        
        print('='*60)
        print('TEST 3: Full Test with Session + Cookie')
        print('='*60)
        
        cookie = os.environ.get('COOKIE', '')
        
        # Create session
        session = requests.Session()
        
        # Headers
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/140.0.0.0',
            'Content-Type': 'application/json',
            'Origin': 'https://live.ecomm-data.com',
            'Referer': 'https://live.ecomm-data.com/schedule/hs'
        }
        
        if cookie:
            headers['Cookie'] = cookie
            print('Cookie provided')
        else:
            print('No cookie in secrets')
        
        # Initialize session
        print('Step 1: Initialize session...')
        main_resp = session.get(
            'https://live.ecomm-data.com/schedule/hs',
            headers={'User-Agent': headers['User-Agent'], 'Cookie': cookie} if cookie else {'User-Agent': headers['User-Agent']},
            timeout=10
        )
        print(f'Main page: {main_resp.status_code}')
        
        # API call
        print('Step 2: API call...')
        date_str = datetime.now().strftime('%y%m%d')
        
        api_resp = session.post(
            'https://live.ecomm-data.com/schedule/list_hs',
            json={'date': date_str},
            headers=headers,
            timeout=10
        )
        
        print(f'API status: {api_resp.status_code}')
        
        if api_resp.status_code == 200:
            data = api_resp.json()
            if 'list' in data:
                items = data['list']
                with_sales = sum(1 for item in items if item.get('sales_amt') not in [None, 0])
                print(f'Results: {len(items)} items, {with_sales} with sales')
                
                if with_sales > 0:
                    print('SUCCESS: Sales data available!')
                    for item in items[:3]:
                        if item.get('sales_amt'):
                            print(f'  Sample: {item.get("sales_amt")} won')
                            break
                else:
                    print('WARNING: No sales data')
        PYTHON_SCRIPT
    
    - name: Test 4 - Check GitHub IP
      run: |
        python3 << 'PYTHON_SCRIPT'
        import requests
        
        print('='*60)
        print('TEST 4: GitHub Actions IP Information')
        print('='*60)
        
        ip_resp = requests.get('https://api.ipify.org?format=json')
        ip = ip_resp.json()['ip']
        print(f'GitHub Actions IP: {ip}')
        
        info_resp = requests.get(f'http://ip-api.com/json/{ip}')
        info = info_resp.json()
        print(f'Location: {info.get("country")}, {info.get("city")}')
        print(f'ISP: {info.get("isp")}')
        print(f'Org: {info.get("org")}')
        
        if 'GitHub' in info.get('org', '') or 'Microsoft' in info.get('org', ''):
            print('WARNING: Identifiable as GitHub/Microsoft datacenter')
        PYTHON_SCRIPT
    
    - name: Summary
      if: always()
      run: |
        echo "## Test Complete"
        echo "Check the logs above for results"
        echo ""
        echo "If all tests pass:"
        echo "1. Add LABANGBA_COOKIE to repository secrets"
        echo "2. Use the main crawling workflow"
        echo ""
        echo "If tests fail:"
        echo "- Consider self-hosted runner"
        echo "- Or use local crawling + GitHub backup"
